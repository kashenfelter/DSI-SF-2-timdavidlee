{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project:  Indeed NLP Analysis /w Scrapy\n",
    "\n",
    "Today we will break into groups to look at the global data science job market from indeed.  You will be extending the work on an existing spider project and working with NLP.\n",
    "\n",
    "The following insights are required from all Groups:\n",
    "\n",
    " - Top hiring companies\n",
    " - Counts of \"skill\" keywords (ie: Statistics, Python, Machine Learning, Big Data, etc)\n",
    " - Prediction of \"data scientists\" job titles against job titles not labeled \"data scientist\"\n",
    "   - Capture the probability predictions of your model, put it back in your dataframe, sort to see top predicted jobs that are not labeld \"data scientist\".  Further extend your analsysis from here to see which are most common or most likely.  What are the insights from this?\n",
    " \n",
    "BONUS:\n",
    " - Perform LDA on job summaries.\n",
    " \n",
    "Advice:\n",
    " - Create a feature that takes the value 0 or 1 if the title is \"Data Scientist\".\n",
    " - Develop an xpath feature that extracts the company name in the spider.\n",
    " - Set your DOWNLOAD_DELAY in your settings.py file to 4 and debug your queries 1st.  Then remove the delay once you want to scrape the whole site.\n",
    " - Use CountVectorizer, and compare with TFIDFVectorizer\n",
    " - Vectorize the summary as your X, and the 0 / 1 feature from your dataframe as your **y**\n",
    " - LogisticRegression is a good place to start with modeling.\n",
    "\n",
    "Use this spider to start your analysis.  Be mindful of the rate default in your settings file!\n",
    "https://gist.github.com/dyerrington/902b13d3b128cd211b5059039714e798\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 1:  San Francisco\n",
    "\n",
    "Work with the New York Group to investigate what skills are important in each market but most importantly \"why\" they might be.  Is there anything else different from New York vs San Francisco that you can draw on?\n",
    "\n",
    "Otherwise, complete the required insights for your presentation.  Pick someone to present that hasn't presented during a group activity yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 2:  New York\n",
    "\n",
    "Work with the San Francisco group use their data to help classify your regional market requirement of classifying data scientist jobs.  Is there anything different from New York vs San Francisco in terms of what is predicted outside of the \"data scientist\" job title?\n",
    "\n",
    "Otherwise, complete the required insights for your presentation.  Pick someone to present that hasn't presented during a group activity yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 3:  United States\n",
    "\n",
    "Work with the International group to compare skill keywords. Is there anything different about the US compared to markets outside the US?  Are some job requirements more emphasised than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2128, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Machine Learning Scientist</td>\n",
       "      <td>Data Scientist / Machine Learning Scientist. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Research Engineer* (Maplewood, MN) Job</td>\n",
       "      <td>\\nData handling and analytics. The Research En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scientist - Analytical R&amp;D</td>\n",
       "      <td>\\nThe Associate Scientist / Scientist will pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Eden Prairie, MN</td>\n",
       "      <td>\\nData Scientists work closely with the Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Statistician</td>\n",
       "      <td>\\nProvide thought leadership and project leade...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0  Data Scientist / Machine Learning Scientist   \n",
       "1       Research Engineer* (Maplewood, MN) Job   \n",
       "2                   Scientist - Analytical R&D   \n",
       "3            Data Scientist - Eden Prairie, MN   \n",
       "4                          Senior Statistician   \n",
       "\n",
       "                                             summary  \n",
       "0  Data Scientist / Machine Learning Scientist. S...  \n",
       "1  \\nData handling and analytics. The Research En...  \n",
       "2  \\nThe Associate Scientist / Scientist will pro...  \n",
       "3  \\nData Scientists work closely with the Busine...  \n",
       "4  \\nProvide thought leadership and project leade...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"results.csv\")\n",
    "print df.shape\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'Data Scientist / Machine Learning Scientist. Strong knowledge of computer vision, sensor data fusion and analytics, and machine learning algorithms with proven...'\n",
      " '\\nData handling and analytics. The Research Engineer will be part of a team of scientists and technicians using approximately 90 weathering machines to study 3M...'\n",
      " '\\nThe Associate Scientist / Scientist will provide technical support to assigned projects, using robust scientific methods which comply with standard operating...'\n",
      " '\\nData Scientists work closely with the Business, data stewards, scrum masters, project managers, and other software teams to turn data into actionable signals...'\n",
      " '\\nProvide thought leadership and project leadership to develop advanced analytic methodologies to detect patterns in mid- and large-scale clinical, product...']\n"
     ]
    }
   ],
   "source": [
    "summary_only = df.summary.values\n",
    "print summary_only[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data          2403\n",
       "scientist      701\n",
       "machine        622\n",
       "learning       568\n",
       "sensor         135\n",
       "algorithms     245\n",
       "fusion         130\n",
       "proven         137\n",
       "strong         184\n",
       "computer       185\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======================================  count vectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer(stop_words='english')\n",
    "cvec.fit(summary_only)\n",
    "\n",
    "\n",
    "df2  = pd.DataFrame(cvec.transform(summary_only).todense(),\n",
    "              columns=cvec.get_feature_names())\n",
    "X = df2.transpose().sort_values(0, ascending=False).head(30).transpose()\n",
    "\n",
    "\n",
    "df2.transpose().sort_values(0, ascending=False).head(10).transpose().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['data_scientist'] = df['title'].map(lambda x: 1 if 'data scientist' in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2128,)\n"
     ]
    }
   ],
   "source": [
    "y = df['data_scientist'].values\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>scientist</th>\n",
       "      <th>machine</th>\n",
       "      <th>learning</th>\n",
       "      <th>sensor</th>\n",
       "      <th>algorithms</th>\n",
       "      <th>fusion</th>\n",
       "      <th>proven</th>\n",
       "      <th>strong</th>\n",
       "      <th>computer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    data  scientist  machine  learning  sensor  algorithms  fusion  proven  \\\n",
       "0      2          2        2         2       1           1       1       1   \n",
       "1      1          0        0         0       0           0       0       0   \n",
       "2      0          2        0         0       0           0       0       0   \n",
       "3      3          0        0         0       0           0       0       0   \n",
       "4      0          0        0         0       0           0       0       0   \n",
       "5      0          2        0         0       0           0       0       0   \n",
       "6      0          0        0         0       0           0       0       0   \n",
       "7      1          0        0         0       0           0       0       0   \n",
       "8      3          0        0         0       0           0       0       0   \n",
       "9      2          0        0         0       0           0       0       0   \n",
       "10     2          0        0         0       0           0       0       0   \n",
       "11     2          0        0         0       0           0       0       0   \n",
       "12     2          2        2         2       1           1       1       1   \n",
       "13     1          0        0         0       0           0       0       0   \n",
       "14     0          2        0         0       0           0       0       0   \n",
       "15     3          0        0         0       0           0       0       0   \n",
       "16     0          0        0         0       0           0       0       0   \n",
       "17     0          2        0         0       0           0       0       0   \n",
       "18     0          0        0         0       0           0       0       0   \n",
       "19     1          0        0         0       0           0       0       0   \n",
       "\n",
       "    strong  computer  \n",
       "0        1         1  \n",
       "1        0         0  \n",
       "2        0         0  \n",
       "3        0         0  \n",
       "4        0         0  \n",
       "5        0         0  \n",
       "6        0         0  \n",
       "7        0         0  \n",
       "8        0         0  \n",
       "9        0         0  \n",
       "10       0         0  \n",
       "11       0         0  \n",
       "12       1         1  \n",
       "13       0         0  \n",
       "14       0         0  \n",
       "15       0         0  \n",
       "16       0         0  \n",
       "17       0         0  \n",
       "18       0         0  \n",
       "19       0         0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2128,) (2128, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781015037594\n",
      "0.801221804511\n",
      "0.789473684211\n",
      "           features  rfc1      rfc2      rfc3\n",
      "2           machine  0.14  0.218404  0.212772\n",
      "1         scientist  0.14  0.170834  0.199730\n",
      "5        algorithms  0.15  0.078912  0.121136\n",
      "3          learning  0.10  0.166266  0.104081\n",
      "0              data  0.10  0.102085  0.098223\n",
      "6            fusion  0.09  0.058508  0.073856\n",
      "7            proven  0.04  0.052357  0.048582\n",
      "12        analytics  0.03  0.041762  0.040878\n",
      "4            sensor  0.07  0.027587  0.031076\n",
      "11           vision  0.04  0.053350  0.023990\n",
      "9          computer  0.03  0.004602  0.022478\n",
      "8            strong  0.02  0.016521  0.017309\n",
      "10        knowledge  0.01  0.005777  0.002045\n",
      "24  personalization  0.00  0.000480  0.001211\n",
      "14       performing  0.02  0.001351  0.000954\n",
      "23          perform  0.01  0.000120  0.000619\n",
      "22           person  0.01  0.000152  0.000485\n",
      "13        performed  0.00  0.000713  0.000286\n",
      "28      perspective  0.00  0.000000  0.000140\n",
      "18             perl  0.00  0.000014  0.000046\n",
      "20       permitting  0.00  0.000000  0.000043\n",
      "25       personally  0.00  0.000041  0.000042\n",
      "16         performs  0.00  0.000151  0.000019\n",
      "27          persons  0.00  0.000000  0.000000\n",
      "26        personnel  0.00  0.000010  0.000000\n",
      "15           permit  0.00  0.000000  0.000000\n",
      "21      persistence  0.00  0.000000  0.000000\n",
      "19         personal  0.00  0.000000  0.000000\n",
      "17         periodic  0.00  0.000000  0.000000\n",
      "29        pertinent  0.00  0.000000  0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc1 = RandomForestClassifier(n_estimators=100,max_depth=1, verbose=1)\n",
    "rfc2 = RandomForestClassifier(n_estimators=100,max_depth=2, verbose=1)\n",
    "rfc3 = RandomForestClassifier(n_estimators=100,max_depth=2, verbose=1)\n",
    "\n",
    "print y.shape, X.shape\n",
    "\n",
    "rfc1.fit(X,y)\n",
    "rfc2.fit(X,y)\n",
    "rfc3.fit(X,y)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "yhat1 = rfc1.predict(X)\n",
    "yhat2 = rfc2.predict(X)\n",
    "yhat3 = rfc3.predict(X)\n",
    "\n",
    "print rfc1.score(X,y)\n",
    "print rfc2.score(X,y)\n",
    "print rfc3.score(X,y)\n",
    "\n",
    "df3 = pd.DataFrame({'features': X.columns.values, 'rfc1': rfc1.feature_importances_, 'rfc2':rfc2.feature_importances_, 'rfc3':rfc3.feature_importances_ })\n",
    "print df3.sort_values('rfc3',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.316729323308\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 4:  International\n",
    "\n",
    "Generally, you can work with any of the other groups but you must find at least one aspect of data science job market comparison with other groups in order to complete your presentation.  Consider working with the United States group.\n",
    "\n",
    "You may focus on a single market outside of the us.  London appears to be the biggest market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
