{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a basic Random Forest\n",
    "\n",
    "The Random Forest model is a popular bagging ensemble method. It combines many decision tree classifiers or regressors as the \"base models\" to make predictions.\n",
    "\n",
    "By building this ourselves we will get to see the internals of exactly what is going on in a bagging ensemble model.\n",
    "\n",
    "---\n",
    "\n",
    "### Construction of the RF\n",
    "\n",
    "The Random Forest classifier is built such that:\n",
    "\n",
    "1. Multiple internal decision tree classifiers will be built as the base models\n",
    "- For each base model, the data will be resampled like in bootstrapping.\n",
    "- Each decision tree will be fit on the bootstrapped sample of the data.\n",
    "- To predict, each internal base model will be passed the new data and make their predictions. The final output will be a vote across the base models for the class.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine = pd.read_csv('/Users/tlee010/desktop/DSI-SF-2-timdavidlee/datasets/wine_quality/winequality_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Create the random forest class\n",
    "\n",
    "Keyword arguments:\n",
    "\n",
    "    n_estmators\n",
    "    max_depth\n",
    "    max_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomForest(object):\n",
    "    def __init__(self, n_estimators=3, max_depth=None, max_features=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.base_estimators = {}\n",
    "        \n",
    "    \n",
    "    def _make_base_estimator(self,X,y, estimator_number=1):\n",
    "        #make a random sampled version of X, y\n",
    "        #will use indices to get into our random version\n",
    "        row_indices =range(X.shape[0])\n",
    "        random_indices = np.random.choice(row_indices, size= len(row_indices),replace=True)\n",
    "        #print X,y\n",
    "        #print row_indices\n",
    "        #print random_indices\n",
    "        \n",
    "        #make bootstrapped X,y\n",
    "        Xr = X.iloc[random_indices,:]\n",
    "        yr = [y[x] for x in random_indices]\n",
    "        #print Xr\n",
    "        #print yr\n",
    "        \n",
    "        dtc = DecisionTreeClassifier(max_depth=self.max_depth, max_features=self.max_features)\n",
    "        dtc.fit(Xr,yr)\n",
    "        self.base_estimators[estimator_number] = dtc\n",
    "        print dtc.score(Xr,yr)\n",
    "    def fit(self,X,y):\n",
    "        for i in range(self.n_estimators):\n",
    "            self._make_base_estimator(X,y,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 3) 6497\n",
      "0.932738186855\n",
      "0.931660766508\n",
      "0.9318146837\n"
     ]
    }
   ],
   "source": [
    "# X = pd.DataFrame({'a':[1,2,3,4,5,6,7,8]})\n",
    "# y = [1,0,1,0,1,0,1,0]\n",
    "\n",
    "y= wine.red_wine.values\n",
    "X = wine[['quality','alcohol','chlorides']]\n",
    "print X.shape, len(y)\n",
    "rf = RandomForest(n_estimators=3,max_depth=3,max_features=3)\n",
    "#rf._make_base_estimator(X,y)\n",
    "rf.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Write a base model creator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Write a data boostrapping function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Write the fit function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. Write the predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RandomForest(object):\n",
    "    def __init__(self, n_estimators=3, max_depth=None, max_features=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.base_estimators = {}\n",
    "        \n",
    "    \n",
    "    def _make_base_estimator(self,X,y, estimator_number=1):\n",
    "        #make a random sampled version of X, y\n",
    "        #will use indices to get into our random version\n",
    "        row_indices =range(X.shape[0])\n",
    "        random_indices = np.random.choice(row_indices, size= len(row_indices),replace=True)\n",
    "        #print X,y\n",
    "        #print row_indices\n",
    "        #print random_indices\n",
    "        \n",
    "        #make bootstrapped X,y\n",
    "        Xr = X.iloc[random_indices,:]\n",
    "        yr = [y[x] for x in random_indices]\n",
    "        #print Xr\n",
    "        #print yr\n",
    "        \n",
    "        dtc = DecisionTreeClassifier(max_depth=self.max_depth, max_features=self.max_features)\n",
    "        dtc.fit(Xr,yr)\n",
    "        self.base_estimators[estimator_number] = dtc\n",
    "        print dtc.score(Xr,yr)\n",
    "    def fit(self,X,y):\n",
    "        for i in range(self.n_estimators):\n",
    "            self._make_base_estimator(X,y,i)\n",
    "            \n",
    "    def predict(self,X,y):\n",
    "        predictions = []\n",
    "        for i in range(self.n_estimators):\n",
    "            base_model = self.base_estimators[i]\n",
    "            current_pred = base_model.predict(X)\n",
    "            predictions.append(current_pred)\n",
    "        voted_class = []\n",
    "        predictor_length = X.shape[0]\n",
    "        \n",
    "        for predict in range(predictor_length):\n",
    "            ones = 0\n",
    "            for i in range(self.n_estimators):\n",
    "                ones += predictions[pred]\n",
    "            if ones > (self.n_estimators/2.):\n",
    "                voted_class.append(1)\n",
    "            else:\n",
    "                voted_class.append(0)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6. Test on the wine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 3) 6497\n",
      "0.933969524396\n",
      "0.926581499153\n",
      "0.924734492843\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y= wine.red_wine.values\n",
    "X = wine[['quality','alcohol','chlorides']]\n",
    "print X.shape, len(y)\n",
    "rf = RandomForest(n_estimators=3,max_depth=3,max_features=3)\n",
    "#rf._make_base_estimator(X,y)\n",
    "rf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
