{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import cPickle as pickle\n",
    "import unidecode\n",
    "\n",
    "\n",
    "# takes in list of text fields, manipulates them\n",
    "\n",
    "class hardSkillParser(object):\n",
    "\n",
    "\n",
    "    def __init__(self,list_of_text):\n",
    "        #expecting a single value data frame\n",
    "        self.text_dict = [{'text':self._fixText(x)} for x in list_of_text] \n",
    "        \n",
    "    def load(self,list_of_text):\n",
    "        self.text_dict = [{'text':self._fixText(x)} for x in list_of_text]\n",
    "        \n",
    "#===========================================================================        \n",
    "#===========================================================================        \n",
    "#===========================================================================        \n",
    "#===========================================================================\n",
    "    # some of hte HTML data that was pulled needs to be \n",
    "    # decoded from unicode and either falls in one of the\n",
    "    # two combinations: decode UTF8 then UNICODE decode\n",
    "    \n",
    "    def _fixText(self, input_string):\n",
    "        prevlower = False\n",
    "        newText = ''\n",
    "        for x in input_string:\n",
    "            if x=='*':\n",
    "                newText +='\\n'\n",
    "            elif x.isalpha()==False:\n",
    "                prevlower=0\n",
    "            elif x.islower():\n",
    "                prevlower = True\n",
    "\n",
    "            if (prevlower == True) & (x.isupper()):\n",
    "                newText += '.\\n' + x\n",
    "                prevlower = False        \n",
    "            else:\n",
    "                newText += x\n",
    "        return newText\n",
    "            \n",
    "            \n",
    "    # similar to the previous function but \n",
    "    # designed for pandas MAP and APPLY functions\n",
    "    \n",
    "    def _cleanLI(self, yy):\n",
    "        newlist = []\n",
    "        for y in yy:\n",
    "            try:\n",
    "                newlist.append(unidecode.unidecode(y.decode('utf-8')).lower())\n",
    "            except:\n",
    "                try:\n",
    "                    newlist.append(y.decode('utf-8').lower())\n",
    "                except:\n",
    "                    newlist.append(y.lower())\n",
    "        return newlist       \n",
    "   \n",
    "    \n",
    "    # =========================================================\n",
    "    # pulls newline delinated lines, since these are typically\n",
    "    # the bullet point descriptions\n",
    "    # and have a higher percentage of relevant details\n",
    "    # relating to job instead of disclaimers, or \n",
    "    # company background or descriptions\n",
    "    \n",
    "    def _parseLI(self,y):\n",
    "        LI = []\n",
    "        y  = y.replace('i.e.','-ie-').replace('e.g.','-eg-')\n",
    "        for x in y.split('\\n'):\n",
    "            ct = len(x.strip().split('.'))\n",
    "            if ct ==1:\n",
    "                if len(x)>0:\n",
    "                    LI.append(x)\n",
    "            elif len(x.strip().split('.')[1])<=1:\n",
    "                if len(x.strip().split('.')[0])>0:\n",
    "                    LI.append(x.strip().split('.')[0])\n",
    "        return LI\n",
    "\n",
    "    # =========================================================    \n",
    "    # this will provide a second level of detail\n",
    "    # from the LI items pulled, this will go through and further\n",
    "    # pull out more hard topics\n",
    "    \n",
    "    def _splitLI(self,y,phrase):\n",
    "        try:\n",
    "            if phrase in ('to','in'):\n",
    "                return y.split(' '+phrase+' ')[1]\n",
    "            else:\n",
    "                return y.split(phrase)[1]\n",
    "        except:\n",
    "            return ''\n",
    "\n",
    "#===========================================================================        \n",
    "#===========================================================================        \n",
    "#===========================================================================        \n",
    "#===========================================================================\n",
    "     \n",
    "    def fit(self):\n",
    "        start = datetime.datetime.now()\n",
    "        terms = ['in','including','knowledge of','experience with', 'understanding of', 'to','develop ','design ','requirements']\n",
    "        for x in self.text_dict:\n",
    "            x['LI'] =self._cleanLI(self._parseLI(x['text']))\n",
    "            hardskill = []\n",
    "            for y in terms:\n",
    "                x[y] = [self._splitLI(LI,y) for LI in x['LI']]\n",
    "                x[y] = [z for z in x[y] if z!='']\n",
    "                hardskill.extend(x[y])\n",
    "            x['hardskill'] = hardskill\n",
    "            x['LI_text'] = ' '.join(x['LI'])\n",
    "            x['hardskill_text'] = ' '.join(x['hardskill'])\n",
    "        print datetime.datetime.now()-start\n",
    "        \n",
    "        self.parsed_df = pd.DataFrame(self.text_dict)[['text','LI','hardskill']]\n",
    "    \n",
    "    def save(self):\n",
    "        with open(\"008_parsed_text_dict.p\",'wb') as f:\n",
    "            pickle.dump(self.text_dict,f)\n",
    "        with open(\"008_parsed_df.p\",'wb') as f:\n",
    "            pickle.dump(self.parsed_df,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('master_total_df.p','rb') as f:\n",
    "    master_total_df = pickle.load(f)\n",
    "    \n",
    "alltext = master_total_df['jobdesc'].values\n",
    "sometext = alltext[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.035503\n"
     ]
    }
   ],
   "source": [
    "hSP = hardSkillParser(sometext)\n",
    "hSP.fit()\n",
    "hSP.parsed_df\n",
    "hSP.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nData Analyst\\xe2\\x80\\xafWe\\xe2\\x80\\x99re looking for a Data Analyst with initiative and curiosity who can find, analyze and summarize data in ways that tell a story underlying data. The successful candidate will be a key part of a team that is focused on supporting elementary math teachers. This analyst will have autonomy to lead data collection initiatives with access to robust data sets and analysis tools.\\xe2\\x80\\xafTo be successful, you\\xe2\\x80\\x99ll be empowered to:Turn important questions into researchable hypotheses along with an achievable data collection and evaluation plan.\\nTake initiative to mine various data sources, looking for interesting relationships, important correlations, and notable non-correlations.\\nCreate your own hypotheses and research questions within the context of the project and explore them.\\nFind and interpret data, analyze results using statistical techniques, and provide ongoing reports that tell the story behind the data.\\nTurn data and information into insights by identifying, analyzing, and interpreting trends or patterns in complex data sets\\xe2\\x80\\xafRequirements:3+ years of industry experience solving analytical problems using quantitative approaches and a strong knowledge of statistics.\\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.\\nExperience with R, SAS, or Python statistical packages preferred.\\nAdvanced Modeling skills along with experience using statistical packages for analyzing large datasets.\\nProficient in SQLAdept at data queries, report writing and presenting findings.\\nAbility to clearly convey complex information to others and make it understood using Excel and/or Tableau.\\nRequired education:Bachelor's.\\nRequired experience:SQL: 2 years\\n\\n3 \""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = hSP.parsed_df.iloc[16,:]['text']\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Analyst We’re looking for a Data Analyst with initiative and curiosity who can find, analyze and summarize data in ways that tell a story underlying data. The successful candidate will be a key part of a team that is focused on supporting elementary math teachers. This analyst will have autonomy to lead data collection initiatives with access to robust data sets and analysis tools. To be successful, you’ll be empowered to:Turn important questions into researchable hypotheses along with an achievable data collection and evaluation plan.\n",
      "Take initiative to mine various data sources, looking for interesting relationships, important correlations, and notable non-correlations.\n",
      "Create your own hypotheses and research questions within the context of the project and explore them.\n",
      "Find and interpret data, analyze results using statistical techniques, and provide ongoing reports that tell the story behind the data.\n",
      "Turn data and information into insights by identifying, analyzing, and interpreting trends or patterns in complex data sets Requirements:3+ years of industry experience solving analytical problems using quantitative approaches and a strong knowledge of statistics.\n",
      "Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.\n",
      "Experience with R, SAS, or Python statistical packages preferred.\n",
      "Advanced Modeling skills along with experience using statistical packages for analyzing large datasets.\n",
      "Proficient in SQLAdept at data queries, report writing and presenting findings.\n",
      "Ability to clearly convey complex information to others and make it understood using Excel and/or Tableau.\n",
      "Required education:Bachelor's.\n",
      "Required experience:SQL: 2 years\n",
      "\n",
      "3 \n"
     ]
    }
   ],
   "source": [
    "prevlower = False\n",
    "newText = ''\n",
    "for x in test_text:\n",
    "    if x=='*':\n",
    "        newText +='\\n'\n",
    "    elif x.isalpha()==False:\n",
    "        prevlower=0\n",
    "    elif x.islower():\n",
    "        prevlower = True\n",
    "        \n",
    "    if (prevlower == True) & (x.isupper()):\n",
    "        newText += '.\\n' + x\n",
    "        prevlower = False        \n",
    "    else:\n",
    "        newText += x\n",
    "\n",
    "print newText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
