{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Jobs: EDA Preliminary Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement: finding treasure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**\n",
    "\n",
    "Searching for new jobs can be an arduous process. The diligent can get through 10-20 per week, and the hit rate may not be that high. If the job search goes for 2 months, thats around 150 job postings. From my initial search, there are 1000s of data science/ data analyst positions, and many more similar positions under business and product engineers. So can data science help data scientists find jobs?\n",
    "\n",
    "Assumption: NLP can be used with the detailed job descriptions to \n",
    "1. find correct titles (if any) for job descriptions\n",
    "2. recommend similar jobs \n",
    "3. cluster similar job skills extracted from these job descriptions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Part 1: Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goals : Pull job postings for possible data science-related careers\n",
    "\n",
    "\n",
    "**Terms Searched for:**\n",
    "- \"Data Science\"\n",
    "- \"Data Scientist\"\n",
    "- \"Data Analyst\"\n",
    "- \"Data Engineer\"\n",
    "- \"Business Analyst\"\n",
    "- \"Machine Learning\"\n",
    "- \"Statistics\"\n",
    "- \"Product Analyst\"\n",
    "- \"Deep Learning\"\n",
    "\n",
    "**Cities/Locations**\n",
    "- San Francisco, CA\n",
    "- Mountain View, CA\n",
    "- Seattle, WA\n",
    "- Los Angeles, CA\n",
    "- Boston, MA\n",
    "- New York, NY\n",
    "- Philadelphia, PN\n",
    "- Washington, DC\n",
    "- Atlanta, GA\n",
    "- Houston, TX\n",
    "- Austin, TX\n",
    "- Chicago, IL\n",
    "- Minneapolis, MN\n",
    "\n",
    "**Job Website 1:** the website has an API. Python was used to pull job listing urls, but just has titles, company names, cities, and states. Python, requests library was used to pull from the API. From those links, python with selenium was used to pull job description details. 50,000 job postings were pulled **Notes:** Noted in the EDA, but a majority of the job postings were duplicates, after de-duping, the total unique postings were around 14,000. \n",
    "\n",
    "**Process**\n",
    "1. Get API key by registering\n",
    "2. Write python looper for ~14 different cities, using same API search string (no max for search results)\n",
    "3. For each search string, pull all possible results using python to go through the pagination\n",
    "4. Save all the individual job links (~50,000)\n",
    "5. Start 2nd crawler to pull jobdescription details for the remaining jobs\n",
    "\n",
    "\n",
    "**Job Website 2:** the website does not have an API, so for both the job links and the job descriptions, selenium was used over a period of 2 weeks at a slow 20sec delay to pull 14,000 job postings. Due to website security and blocking, scraping was very slow, and had to be restarted multiple times. Search results were capped at 40 pages x 25 results per page = 1000 search results. As a result a list of ~ 14 cities x ~10 search terms were used to make ~140 unique searches.\n",
    "\n",
    "**Process**\n",
    "1. Test website limitis\n",
    "2. Write python looper for 140 different search combinations\n",
    "3. For each search string, pull all possible results using selenium to go through the pagination\n",
    "4. Save all the individual job links (~14,000)\n",
    "5. Start 2nd crawler to pull jobdescription details for the remaining jobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample API Link\n",
    "http://api.indeed.com/ads/apisearch?publisher=2313019136084570&q=%22data+analyst%22+OR+%22data+scientist%22+OR+%22data+science%22+OR+%22business+analyst%22+or+%22Analytics%22&l=San+Francisco%2C+CA&st=&jt=fulltime&start=0&limit=20&fromage=60&latlong=1&co=us&userip=1.2.3.4&useragent=Mozilla/%2F4.0%28Firefox%29&v=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample API Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "{u'response': {u'@version': 2,\n",
    "  u'clickedCategories': {},\n",
    "  u'dupefilter': {u'$': True},\n",
    "  u'end': {u'$': 25},\n",
    "  u'highlight': {u'$': False},\n",
    "  u'location': {u'$': u'San Jose, CA'},\n",
    "  u'pageNumber': {u'$': 0},\n",
    "  u'paginationPayload': {},\n",
    "  u'query': {u'$': u'\"data analyst\" OR \"data scientist\" OR \"data science\" OR \"business analyst\" or \"Analytics\"'},\n",
    "  u'radius': {u'$': 25},\n",
    "  u'results': {u'result': [{u'city': {u'$': u'San Jose'},\n",
    "     u'company': {u'$': u'Adobe'},\n",
    "     u'country': {u'$': u'US'},\n",
    "     u'date': {u'$': u'Mon, 08 Aug 2016 19:52:38 GMT'},\n",
    "     u'expired': {u'$': False},\n",
    "     u'formattedLocation': {u'$': u'San Jose, CA'},\n",
    "     u'formattedLocationFull': {u'$': u'San Jose, CA'},\n",
    "     u'formattedRelativeTime': {u'$': u'30+ days ago'},\n",
    "     u'indeedApply': {u'$': False},\n",
    "     u'jobkey': {u'$': u'788848ad2706b267'},\n",
    "     u'jobtitle': {u'$': u'Business Systems Analyst'},\n",
    "     u'latitude': {u'$': 37.337914},\n",
    "     u'longitude': {u'$': -121.89011},\n",
    "     u'onmousedown': {u'$': u\"indeed_clk(this,'2086');\"},\n",
    "     u'snippet': {u'$': u'The Adobe Information, Data and services Business Solutions Analyst (BSA) will be responsible for collaborating with IT and business clients to understand key...'},\n",
    "     u'source': {u'$': u'Adobe'},\n",
    "     u'sponsored': {u'$': False},\n",
    "     u'state': {u'$': u'CA'},\n",
    "     u'url': {u'$': u'http://www.indeed.com/viewjob?jk=788848ad2706b267&qd=I0TxM_wMPz_iqziD0cGR0PxLjuFXC0PsEfAsModHF2st56MW-C4_aRZZ49ZIFQT7Q6T0dt0aQ-pjLjZ1rU0TrrgvjzJLVDraSv5jRUBSQRE4rzSPTGVAZrn57D8I7-iZPPOnyqkZAWHSsZVuWLMMyGdT8RqGX3zRviuHfoN9_16z9Y5HrDbNczadbi7F-QkeLN4wjpfgfMVbIHjTO97TuDfgwv9wD6L4u89hEa7BM75_dbjB9DmsoKYh9Vr0WnfH&indpubnum=2313019136084570&atk=1asm1jak9b9rkajg'}\n",
    "                           }]}}}\n",
    "```        \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample job desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````\n",
    "-------------------------------------------------------------------------------------------------\n",
    "We’re looking for Data Engineers to put complex algorithms and data models into production.\n",
    "-------------------------------------------------------------------------------------------------\n",
    "Kabbage s looking to hire a Data Engineer to to put complex algorithms and data models into production. This is a particularly exciting phase, as Kabbage offers the only fully automated, online lending platform designed to support continuous customer data monitoring. We serve small businesses and consumers directly through Kabbage.com and Karrot.com and power lending for organizations all over the globe.\n",
    "---------------------------------------------\n",
    "Day in the life of a Data Engineer at Kabbage\n",
    "---------------------------------------------\n",
    "\n",
    "Skills & Experience\n",
    "-----------------------\n",
    "\n",
    "Some of the things we're looking for in you\n",
    "-------------------------------------------\n",
    "\n",
    "\n",
    "Of course we have all of the requisite goodies: unlimited food and beverages (of all kinds), lunch catered daily, regular ping pong tournaments, free parking and white boards filled with questionable drawings. More than that, we have a pretty tight team of passionate, driven individuals with whom you wouldn't mind spending a big part of your day.\n",
    "#36 on the Inc. 500 | Fast Company’s \"Top 10 Most Innovative Companies in Finance\" | Business Insider's \"Top 20 Unicorn Startups to Work For\" | Forbes' \"America’s 100 Most Promising Companies\" | AJC's \"Top Places to Work\"\n",
    "Kabbage is an equal opportunity employer. At Kabbage we make all employment decisions, which include hiring, promoting, transferring, demoting, evaluating, compensating and separating, without regard to sex, sexual orientation, gender identity, race, color, religion, age, national origin, pregnancy, citizenship, disability, service in the uniform services, or any other classification protected by federal, state or local law.\n",
    "*******************************************************\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "We’re looking for Data Engineers to put complex algorithms and data models into production.\n",
    "-------------------------------------------------------------------------------------------------\n",
    "\n",
    "Kabbage s looking to hire a Data Engineer to to put complex algorithms and data models into production. This is a particularly exciting phase, as Kabbage offers the only fully automated, online lending platform designed to support continuous customer data monitoring. We serve small businesses and consumers directly through Kabbage.com and Karrot.com and power lending for organizations all over the globe.\n",
    "\n",
    "---------------------------------------------\n",
    "Day in the life of a Data Engineer at Kabbage\n",
    "---------------------------------------------\n",
    "\n",
    "\n",
    "Design and develop ETL packages from our source systems that are scalable\n",
    "Manage a large-scale data Hadoop platform supporting terabytes of data growing rapidly\n",
    "Analyze complex data systems and elements, data flow, relationships and dependencies to contribute to conceptual, logical and physical data models\n",
    "Perform thorough testing and validation to support the accuracy of data transformations, data verification used in the machine learning models\n",
    "Ensure data quality and governance, create/maintain data dictionary and related metadata\n",
    "Lead innovation by exploration, recommendation, benchmarking and implementing big data technologies for the platform\n",
    "Provide support to the entire analytics team for their data centric needs\n",
    "\n",
    "Skills & Experience\n",
    "-----------------------\n",
    "\n",
    "\n",
    "Experience in Hadoop and MapReduce\n",
    "Familiarity with Hive, Oozie, HBase and related technologies\n",
    "Proficiency in programming in Python, SQL, shell scripting and Java\n",
    "3+ years in using big data technologies and proven ability to work with complex data systems\n",
    "Bachelor’s Degree in Computer Science, Math or related disciplines with 4+ years industry experience OR Master’s Degree with 2+ years experience\n",
    "Strong experience in design and development of large scale applications\n",
    "Strong ability to collaborate with team members throughout the process and consult with other project teams on the design and use of enterprise data\n",
    "Proven ability to create and maintain online and printed documentation\n",
    "Aptitude to independently learn new technologies\n",
    "Excellent written and oral communication skills and a desire to educate co-workers and business users about our data and how to access it\n",
    "\n",
    "Some of the things we're looking for in you\n",
    "-------------------------------------------\n",
    "\n",
    "\n",
    "Highly motivated to tackle multiple projects in parallel\n",
    "Aptitude to independently learn new technologies\n",
    "Excellent written and oral communication skills and ability to share findings with a large, non-technical audience\n",
    "An excellent communicator, teacher and student\n",
    "A perfectionist who tempers it with deadlines\n",
    "\n",
    "The environment: Of course we have all of the requisite goodies: unlimited food and beverages (of all kinds), lunch catered daily, regular ping pong tournaments, free parking and white boards filled with questionable drawings. More than that, we have a pretty tight team of passionate, driven individuals with whom you wouldn't mind spending a big part of your day.\n",
    "\n",
    "#36 on the Inc. 500 | Fast Company’s \"Top 10 Most Innovative Companies in Finance\" | Business Insider's \"Top 20 Unicorn Startups to Work For\" | Forbes' \"America’s 100 Most Promising Companies\" | AJC's \"Top Places to Work\"\n",
    "\n",
    "Kabbage is an equal opportunity employer. At Kabbage we make all employment decisions, which include hiring, promoting, transferring, demoting, evaluating, compensating and separating, without regard to sex, sexual orientation, gender identity, race, color, religion, age, national origin, pregnancy, citizenship, disability, service in the uniform services, or any other classification protected by federal, state or local law.\n",
    "\n",
    "13 days ago  - save job\n",
    " - \n",
    "                original job\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "» Apply Now\n",
    "\n",
    "            Please review all application instructions before applying to Kabbage.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Recommended Jobs\n",
    "\n",
    "Data Engineer\n",
    "\n",
    "Trivoca Consulting -\n",
    "\t\t Atlanta, GA\n",
    "11 days ago\n",
    "Big Data Engineer\n",
    "\n",
    "CapTech Consulting -\n",
    "\t\t Atlanta, GA\n",
    "6 days ago\n",
    "Big Data Engineer\n",
    "\n",
    "Principle Solutions Group -\n",
    "\t\t Atlanta, GA\n",
    "5 days ago\n",
    "Big Data Engineer\n",
    "\n",
    "Trace Staffing -\n",
    "\t\t Atlanta, GA\n",
    "13 days ago\n",
    "\n",
    " Easily apply\n",
    "Data Engineer\n",
    "\n",
    "Veredus -\n",
    "\t\t Atlanta, GA\n",
    "11 days ago\n",
    "\n",
    " Easily apply\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Part 2: Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Sample Code HTML extraction by Beautiful Soup**\n",
    "```\n",
    "with open(singlefile, 'rb') as f:\n",
    "        loaded = pickle.load(f)\n",
    "    print len(loaded)\n",
    "    for record in loaded:\n",
    "        i+=1\n",
    "        print i,\n",
    "        row ={}\n",
    "        row['head-title'] = record['title']\n",
    "        row['head-company'] = record['company']       \n",
    "        row['head-jobid'] = record['jobid']\n",
    "        row['link'] = record['link']\n",
    "        row['head-location'] = record['location']\n",
    "        row['searchlink'] = record['searchlink']\n",
    "        \n",
    "        soup = BeautifulSoup(record['fullHTML'],'lxml')\n",
    "        for br in soup.find_all('br'):\n",
    "            br.replace_with('\\n')\n",
    "        #print soup.prettify()\n",
    "        title_e = soup.find_all('title')\n",
    "        elements = {\n",
    "            'page-title': title_e[0]            \n",
    "            ,'body-jobname': soup.find(itemprop='title')\n",
    "            ,'body-company': soup.find(itemprop='name')\n",
    "            ,'body-location': soup.find(itemprop='addressLocality')\n",
    "            ,'industry': soup.find(itemprop='industry')\n",
    "            ,'employment': soup.find(itemprop='employmentType')\n",
    "            ,'experience': soup.find(itemprop='experienceRequirements')\n",
    "            ,'jobcat': soup.find(itemprop='occupationalCategory')\n",
    "            ,'jobdesc': soup.find(itemprop='description')\n",
    "            ,'company_desc': soup.find('div',{'class':'description-container'})\n",
    "            ,'views': soup.find('li',{'class':\"views\"})\n",
    "        }\n",
    "        \n",
    "        for k,v in elements.items():\n",
    "            if v!=None:\n",
    "                row[k] = v.get_text()\n",
    "            else:\n",
    "                row[k] = np.nan\n",
    "        \n",
    "        collection_list.append(row)\n",
    "        if i % 100 == 0:\n",
    "            print 'saving files'\n",
    "            with open('lnkcompiled'+'00000'[:-len(str(i))]+str(i)+'.p','wb') as f:\n",
    "                pickle.dump(collection_list,f)\n",
    "            collection_list = []\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body-company</th>\n",
       "      <th>body-jobname</th>\n",
       "      <th>body-location</th>\n",
       "      <th>company_desc</th>\n",
       "      <th>days_posted</th>\n",
       "      <th>employment</th>\n",
       "      <th>experience</th>\n",
       "      <th>head-company</th>\n",
       "      <th>head-jobid</th>\n",
       "      <th>head-location</th>\n",
       "      <th>...</th>\n",
       "      <th>industry</th>\n",
       "      <th>jobcat</th>\n",
       "      <th>jobdesc</th>\n",
       "      <th>link</th>\n",
       "      <th>page-title</th>\n",
       "      <th>post_end_date</th>\n",
       "      <th>post_start_date</th>\n",
       "      <th>searchlink</th>\n",
       "      <th>views</th>\n",
       "      <th>jobkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Python/SQL Analyst</td>\n",
       "      <td>Chicago, IL, US</td>\n",
       "      <td>Jobspring Partners is a nationwide contingency...</td>\n",
       "      <td>Posted 28 days ago</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>11</td>\n",
       "      <td>Chicago, IL, US</td>\n",
       "      <td>...</td>\n",
       "      <td>Staffing and Recruiting</td>\n",
       "      <td>Research</td>\n",
       "      <td>Python/SQL Analyst\\n\\nData Analysts capable of...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/195559462</td>\n",
       "      <td>Python/SQL Analyst Job at Jobspring Partners i...</td>\n",
       "      <td>September 22, 2016</td>\n",
       "      <td>August 23, 2016</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>0</td>\n",
       "      <td>195559462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Broad Institute</td>\n",
       "      <td>Senior Associate Computational Biologist</td>\n",
       "      <td>Cambridge, MA, US</td>\n",
       "      <td>The Broad Institute was launched to pioneer a ...</td>\n",
       "      <td>Posted 13 days ago</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Broad Institute</td>\n",
       "      <td>12</td>\n",
       "      <td>Cambridge, MA, US</td>\n",
       "      <td>...</td>\n",
       "      <td>Biotechnology, Nonprofit Organization Manageme...</td>\n",
       "      <td>Research</td>\n",
       "      <td>The Broad Institute of Harvard and MIT is look...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/196771881</td>\n",
       "      <td>Senior Associate Computational Biologist Job a...</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>September 8, 2016</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>52</td>\n",
       "      <td>196771881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stripe</td>\n",
       "      <td>Compensation Analyst</td>\n",
       "      <td>San Francisco, CA, US</td>\n",
       "      <td>Stripe is a set of tools for building and runn...</td>\n",
       "      <td>Posted 9 days ago</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Stripe</td>\n",
       "      <td>13</td>\n",
       "      <td>San Francisco, CA, US</td>\n",
       "      <td>...</td>\n",
       "      <td>Computer Software, Financial Services, and Int...</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Stripe’s people are its most valuable resource...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/196902956</td>\n",
       "      <td>Compensation Analyst Job at Stripe in San Fran...</td>\n",
       "      <td>October 12, 2016</td>\n",
       "      <td>September 12, 2016</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>83</td>\n",
       "      <td>196902956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Data Engineer, Analytics - Seattle</td>\n",
       "      <td>Seattle -WA -US</td>\n",
       "      <td>Facebook was founded in 2004. Our mission is t...</td>\n",
       "      <td>Posted 9 days ago</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>14</td>\n",
       "      <td>Seattle -WA -US</td>\n",
       "      <td>...</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology,Engineering,Analyst</td>\n",
       "      <td>Facebook was built to help people connect and ...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/172687405</td>\n",
       "      <td>Data Engineer, Analytics - Seattle Job at Face...</td>\n",
       "      <td>October 21, 2016</td>\n",
       "      <td>September 12, 2016</td>\n",
       "      <td>https://www.linkedin.com/jobs/search?keywords=...</td>\n",
       "      <td>1893</td>\n",
       "      <td>172687405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         body-company                              body-jobname  \\\n",
       "0  Jobspring Partners                        Python/SQL Analyst   \n",
       "1     Broad Institute  Senior Associate Computational Biologist   \n",
       "2              Stripe                      Compensation Analyst   \n",
       "3            Facebook        Data Engineer, Analytics - Seattle   \n",
       "\n",
       "           body-location                                       company_desc  \\\n",
       "0        Chicago, IL, US  Jobspring Partners is a nationwide contingency...   \n",
       "1      Cambridge, MA, US  The Broad Institute was launched to pioneer a ...   \n",
       "2  San Francisco, CA, US  Stripe is a set of tools for building and runn...   \n",
       "3        Seattle -WA -US  Facebook was founded in 2004. Our mission is t...   \n",
       "\n",
       "          days_posted employment      experience        head-company  \\\n",
       "0  Posted 28 days ago  Full-time     Entry level  Jobspring Partners   \n",
       "1  Posted 13 days ago  Full-time  Not Applicable     Broad Institute   \n",
       "2   Posted 9 days ago  Full-time       Associate              Stripe   \n",
       "3   Posted 9 days ago  Full-time  Not Applicable            Facebook   \n",
       "\n",
       "   head-jobid          head-location    ...      \\\n",
       "0          11        Chicago, IL, US    ...       \n",
       "1          12      Cambridge, MA, US    ...       \n",
       "2          13  San Francisco, CA, US    ...       \n",
       "3          14        Seattle -WA -US    ...       \n",
       "\n",
       "                                            industry  \\\n",
       "0                            Staffing and Recruiting   \n",
       "1  Biotechnology, Nonprofit Organization Manageme...   \n",
       "2  Computer Software, Financial Services, and Int...   \n",
       "3                                           Internet   \n",
       "\n",
       "                                       jobcat  \\\n",
       "0                                    Research   \n",
       "1                                    Research   \n",
       "2                             Human Resources   \n",
       "3  Information Technology,Engineering,Analyst   \n",
       "\n",
       "                                             jobdesc  \\\n",
       "0  Python/SQL Analyst\\n\\nData Analysts capable of...   \n",
       "1  The Broad Institute of Harvard and MIT is look...   \n",
       "2  Stripe’s people are its most valuable resource...   \n",
       "3  Facebook was built to help people connect and ...   \n",
       "\n",
       "                                           link  \\\n",
       "0  https://www.linkedin.com/jobs/view/195559462   \n",
       "1  https://www.linkedin.com/jobs/view/196771881   \n",
       "2  https://www.linkedin.com/jobs/view/196902956   \n",
       "3  https://www.linkedin.com/jobs/view/172687405   \n",
       "\n",
       "                                          page-title       post_end_date  \\\n",
       "0  Python/SQL Analyst Job at Jobspring Partners i...  September 22, 2016   \n",
       "1  Senior Associate Computational Biologist Job a...     October 8, 2016   \n",
       "2  Compensation Analyst Job at Stripe in San Fran...    October 12, 2016   \n",
       "3  Data Engineer, Analytics - Seattle Job at Face...    October 21, 2016   \n",
       "\n",
       "      post_start_date                                         searchlink  \\\n",
       "0     August 23, 2016  https://www.linkedin.com/jobs/search?keywords=...   \n",
       "1   September 8, 2016  https://www.linkedin.com/jobs/search?keywords=...   \n",
       "2  September 12, 2016  https://www.linkedin.com/jobs/search?keywords=...   \n",
       "3  September 12, 2016  https://www.linkedin.com/jobs/search?keywords=...   \n",
       "\n",
       "  views     jobkey  \n",
       "0     0  195559462  \n",
       "1    52  196771881  \n",
       "2    83  196902956  \n",
       "3  1893  172687405  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "with open('master_lnk_df.p','rb') as f:\n",
    "    master_lnk_df = pickle.load(f)\n",
    "master_lnk_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Part 3: EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process:\n",
    "1. clean the two data sources\n",
    "2. merge the two datasets together with common columns\n",
    "3. extract/normalizing some of the fields, filling blanks\n",
    "4. pull out generic titles (analyst, engineer, scientist..)\n",
    "5. pull out 2-gram version of the titles extended titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "```\n",
    "analyst          9150\n",
    "engineer         4120\n",
    "scientist        1506\n",
    "                 1446\n",
    "manager          1263\n",
    "specialist       1182\n",
    "architect         862\n",
    "developer         729\n",
    "consultant        556\n",
    "associate         439\n",
    "lead              367\n",
    "director          360\n",
    "designer          139\n",
    "assistant         111\n",
    "researcher         94\n",
    "intern             88\n",
    "administrator      73\n",
    "programmer         61\n",
    "accountant         56\n",
    "vp                 46\n",
    "statistician       35\n",
    "editor             24\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "business analyst          4029\n",
    "data analyst              1530\n",
    "software engineer         1285\n",
    "data scientist            1139\n",
    "data engineer             1085\n",
    "analyst                    310\n",
    "systems analyst            294\n",
    "development engineer       266\n",
    "senior consultant          249\n",
    "marketing specialist       188\n",
    "director                   183\n",
    "product manager            178\n",
    "manager                    170\n",
    "senior analyst             155\n",
    "intelligence analyst       146\n",
    "research scientist         139\n",
    "marketing analyst          139\n",
    "data architect             132\n",
    "operations analyst         124\n",
    "project manager            121\n",
    "solution architect         118\n",
    "product analyst            115\n",
    "financial analyst          111\n",
    "senior associate           105\n",
    "learning engineer          105\n",
    "research analyst           102\n",
    "solutions architect         93\n",
    "software developer          88\n",
    "systems engineer            88\n",
    "applied scientist           81\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Part 4: Linear Regression - predicting  no of View counts from NLP-elements "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features that will be used\n",
    "\n",
    "- City\n",
    "- State\n",
    "- Posting start date\n",
    "- Days up\n",
    "- Length of Job description\n",
    "- Company\n",
    "- Position name (generic)\n",
    "- Semi-specific Position Name\n",
    "- Posting Month (start)\n",
    "\n",
    "Even though these are only a few features, because they are categorical, this will turn into a large number of features. For example: \"Apple\", \"IBM\",\"Amazon\" listings in the \"COMPANY\" field will result in 2-3 new features. For 8000 job postings, this will increase to be much larger.\n",
    "\n",
    "If these features are not enough, word analysis will be performed to see if certain words will result in more views of the paragraphs. Will clean the date first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Results\n",
    "model | R2 training score | R2 testscore\n",
    "--------|----------|------------|\n",
    "LassoCV|0.286 |0.142\n",
    "RidgeCV|0.372 |0.189\n",
    "Decision Tree Regressor | 0.407 | 0.078\n",
    "RidgeCV w words |0.347|0.144\n",
    "Decision Tree Regressor w words | 0.407 | -0.049"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "======================================================================================\n",
    "======================================================================================\n",
    "1. loading data\n",
    "0:00:04.043642  of  0:00:04.043650\n",
    "======================================================================================\n",
    "======================================================================================\n",
    "2. cleaning data\n",
    "(22707, 15)\n",
    "(8038, 15)\n",
    "0:00:05.455217  of  0:00:09.498867\n",
    "======================================================================================\n",
    "======================================================================================\n",
    "3. scaling data data\n",
    "0:00:00.017944  of  0:00:09.516811\n",
    "======================================================================================\n",
    "======================================================================================\n",
    "4. splitting X and Y datasets\n",
    "(8038, 4047) (8038,)\n",
    "0:00:00.746515  of  0:00:10.263326\n",
    "======================================================================================\n",
    "======================================================================================\n",
    "4a. train_test_split\n",
    "0:00:00.098361  of  0:00:10.361687\n",
    "======================================================================================\n",
    "======================================================================================\n",
    "begin basic and baseline regressions (without NLP additions) =========\n",
    "5.Performing lasso\n",
    "0.286436230017 0.5856753767\n",
    "train / test score\n",
    "0.141959208326 0.866105745957\n",
    "0:01:17.637280  of  0:01:27.998967\n",
    "======================================================================================\n",
    "======================================================================================\n",
    "6. Performing Ridge\n",
    "0.372487195455 10\n",
    "train / test score\n",
    "0.188878880572 10\n",
    "0:01:54.864978  of  0:03:22.863945\n",
    "======================================================================================\n",
    "======================================================================================\n",
    "7. Performing Decision Tree Regressor\n",
    "0.407789552976\n",
    "test train score\n",
    "0.0781474174699\n",
    "0:00:03.338161  of  0:03:26.202106\n",
    "======================================================================================\n",
    "======================================================================================\n",
    "8. prepping the word data\n",
    "0:00:03.065934  of  0:03:29.268040\n",
    "0:00:03.622710  of  0:03:32.890750\n",
    "======================================================================================\n",
    "======================================================================================\n",
    "begin add in NLP features =========\n",
    "9. merging the top 10,000 most common words; merging with X\n",
    "(8038, 14047)\n",
    "0:00:04.618510  of  0:03:37.509260\n",
    "======================================================================================\n",
    "======================================================================================\n",
    "10. using enhanced data with Ridge\n",
    "ridgeCV - training score\n",
    "0.347754677768 1000\n",
    "ridgeCV - test score\n",
    "0.144250344331 1000\n",
    "0:02:37.631455  of  0:06:15.140715\n",
    "======================================================================================\n",
    "======================================================================================\n",
    "11. using enhanced data with decision tree\n",
    "0.407789552976\n",
    "test train score\n",
    "-0.0490863894688\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Part 5: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features that will be used\n",
    "\n",
    "- City\n",
    "- State\n",
    "- Days up\n",
    "- Length of Job description\n",
    "- Company\n",
    "- Words or Phrases (1-->2 Gram)\n",
    "\n",
    "Adding features and then doing NLP on the job descriptions to identify key word elements which can predict job titles. Then the model will be used to predict the title vs. the job description. This will also be used to infer some clustering or if some job descriptions are possibly mis-matched to their current titles\n",
    "\n",
    "```\n",
    "['analyst' 'business analyst' 'data analyst' 'data architect'\n",
    " 'data engineer' 'data scientist' 'development engineer' 'director'\n",
    " 'financial analyst' 'intelligence analyst' 'learning engineer' 'manager'\n",
    " 'marketing analyst' 'marketing specialist' 'operations analyst'\n",
    " 'product analyst' 'product manager' 'project manager' 'research analyst'\n",
    " 'research scientist' 'senior analyst' 'senior associate'\n",
    " 'senior consultant' 'software engineer' 'solution architect'\n",
    " 'systems analyst']\n",
    "```\n",
    "Current Logistic Regression Score: 0.626"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "====================================================================================================\n",
    "0. loading data\n",
    "task time:  0:00:00.055854 overall 0:00:00.055889\n",
    "====================================================================================================\n",
    "1. start data cleaning\n",
    "task time:  0:00:10.157849 overall 0:00:10.213738\n",
    "====================================================================================================\n",
    "2. process the job description word data for NLP\n",
    "task time:  0:00:16.732239 overall 0:00:26.945977\n",
    "====================================================================================================\n",
    "3. word vectorizing and processing complete\n",
    "expanded_title ~ company + city + state + desc_len -1\n",
    "(12518, 15748)\n",
    "['analyst' 'business analyst' 'data analyst' 'data architect'\n",
    " 'data engineer' 'data scientist' 'development engineer' 'director'\n",
    " 'financial analyst' 'intelligence analyst' 'learning engineer' 'manager'\n",
    " 'marketing analyst' 'marketing specialist' 'operations analyst'\n",
    " 'product analyst' 'product manager' 'project manager' 'research analyst'\n",
    " 'research scientist' 'senior analyst' 'senior associate'\n",
    " 'senior consultant' 'software engineer' 'solution architect'\n",
    " 'systems analyst']\n",
    "(12518, 26)\n",
    "task time:  0:00:02.460229 overall 0:00:29.406206\n",
    "====================================================================================================\n",
    "4. train test and split the data\n",
    "(10014, 15748) (2504, 15748) (10014, 26) (2504, 26)\n",
    "task time:  0:00:00.993279 overall 0:00:30.399485\n",
    "====================================================================================================\n",
    "5. start basic logistic regression\n",
    "0:01:04.628651\n",
    "score: 0.626996805112\n",
    "task time:  0:01:08.933368 overall 0:01:39.332853\n",
    "====================================================================================================\n",
    "6. create feature importance by models SAMPLES\n",
    "============================================================\n",
    "analyst\n",
    "(-0.7294571620125575, 'state[T.other]')\n",
    "(0.60752602170861592, u'nlp_contribute')\n",
    "(0.56008826484315311, u'nlp_applicable')\n",
    "(-0.55330929427153253, u'nlp_machine')\n",
    "(-0.50260812587536741, u'nlp_python')\n",
    "============================================================\n",
    "business analyst\n",
    "(-1.3185233118900246, u'nlp_machine')\n",
    "(-0.63542970482329042, u'nlp_spark')\n",
    "(-0.59549567740698928, u'nlp_entry')\n",
    "(-0.5905707658908671, u'nlp_sapient')\n",
    "(-0.57991409222923129, u'nlp_follows')\n",
    "============================================================\n",
    "data analyst\n",
    "(-0.78851163917594225, u'nlp_phd')\n",
    "(-0.7419060741690171, u'nlp_aws')\n",
    "(-0.70317755107476998, u'nlp_java')\n",
    "(-0.657736632750478, u'nlp_amazon')\n",
    "(0.63353943588904083, u'nlp_excel')\n",
    "============================================================\n",
    "data architect\n",
    "(0.68058302210380006, u'nlp_architecture')\n",
    "(0.61319157673180225, u'nlp_architect')\n",
    "(0.54462427652792267, u'nlp_10')\n",
    "(0.52948853561862586, u'nlp_zipcar')\n",
    "(-0.46109320413764215, 'state[T.other]')\n",
    "============================================================\n",
    "data engineer\n",
    "(0.71850196547062606, u'nlp_etl')\n",
    "(0.62422750215671463, u'nlp_pipelines')\n",
    "(-0.4801069829163066, u'nlp_excel')\n",
    "(-0.42731579742720199, u'nlp_statistical')\n",
    "(0.4253979425387614, u'nlp_warehouse')\n",
    "============================================================\n",
    "data scientist\n",
    "(-0.93358364023154439, u'nlp_30')\n",
    "(-0.87326940157254285, u'nlp_excel')\n",
    "(0.7797469790420245, u'nlp_phd')\n",
    "(0.72062782058667341, u'nlp_python')\n",
    "(0.59399705561080585, u'nlp_statistics')\n",
    "============================================================\n",
    "development engineer\n",
    "(-0.60044002414727149, u'nlp_requirements')\n",
    "(0.57417600056886919, u'nlp_mining')\n",
    "(-0.49781548012691956, u'nlp_com')\n",
    "(0.49676435215758213, u'nlp_teradata')\n",
    "(-0.48700221168771218, u'nlp_management')\n",
    "============================================================\n",
    "director\n",
    "(-0.8149324745716009, u'nlp_30')\n",
    "(0.72353772425633367, u'nlp_leadership')\n",
    "(-0.65769126452244653, u'nlp_join')\n",
    "(0.59732858480159168, u'nlp_managing')\n",
    "(-0.5496765899677305, u'nlp_sql')\n",
    "============================================================\n",
    "financial analyst\n",
    "(0.80860907138264049, u'nlp_financial')\n",
    "(0.5519457583731302, u'nlp_finance')\n",
    "(0.47213540492732753, u'nlp_modeling')\n",
    "(0.44321014920959639, u'nlp_reporting')\n",
    "(-0.41159737232354149, u'nlp_plans')\n",
    "============================================================\n",
    "intelligence analyst\n",
    "(1.3745988769239414, u'nlp_intelligence')\n",
    "(-0.59927251105401635, 'state[T.other]')\n",
    "(0.54551585080260523, u'nlp_dashboards')\n",
    "(-0.49719563769898623, 'state[T.CA]')\n",
    "(-0.48146223842226493, u'nlp_process')\n",
    "============================================================\n",
    "learning engineer\n",
    "(0.98281816984954828, u'nlp_machine')\n",
    "(-0.45697373405838787, u'nlp_years')\n",
    "(0.43540369115115163, u'nlp_ocado')\n",
    "(-0.42000864562103002, 'state[T.other]')\n",
    "(-0.38541587216190587, u'nlp_client')\n",
    "====================================================================================================\n",
    "7. identify top 3 titles per\n",
    "(12518, 26)\n",
    "task time:  0:00:24.687746 overall 0:02:04.262677\n",
    "====================================================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Part 6: Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Topic Modeling\n",
    "```\n",
    "[(0,\n",
    "  u'0.028*data + 0.015*experience + 0.009*business + 0.007*team + 0.007*work + 0.006*years + 0.005*skills + 0.005*design'),\n",
    " (1,\n",
    "  u'0.011*marketing + 0.009*team + 0.008*experience + 0.007*work + 0.007*business + 0.006*analytics + 0.005*new + 0.005*data'),\n",
    " (2,\n",
    "  u'0.017*business + 0.010*experience + 0.009*management + 0.007*work + 0.007*data + 0.007*project + 0.007*requirements + 0.006*skills')]\n",
    "```\n",
    "### 5-Topic Modeling\n",
    "```\n",
    "[(0,\n",
    "  u'0.017*business + 0.009*experience + 0.007*team + 0.007*management + 0.007*work + 0.006*data + 0.006*support + 0.006*financial'),\n",
    " (1,\n",
    "  u'0.031*data + 0.015*experience + 0.009*business + 0.009*team + 0.008*work + 0.006*software + 0.006*development + 0.006*skills'),\n",
    " (2,\n",
    "  u'0.009*data + 0.009*experience + 0.009*business + 0.008*health + 0.007*work + 0.007*systems + 0.006*management + 0.006*analysis'),\n",
    " (3,\n",
    "  u'0.018*marketing + 0.010*data + 0.009*analytics + 0.008*experience + 0.008*team + 0.008*digital + 0.007*work + 0.007*business'),\n",
    " (4,\n",
    "  u'0.017*business + 0.013*experience + 0.011*requirements + 0.011*management + 0.010*project + 0.007*support + 0.007*team + 0.006*development')]\n",
    "```\n",
    "### 10-Topic Modeling\n",
    "```\n",
    "[(0,\n",
    "  u'0.033*data + 0.016*experience + 0.010*team + 0.009*work + 0.008*business + 0.007*analytics + 0.006*software + 0.006*development'),\n",
    " (1,\n",
    "  u'0.024*supply + 0.021*chain + 0.011*sourcing + 0.010*analytics + 0.007*manufacturing + 0.006*business + 0.006*planning + 0.005*team'),\n",
    " (2,\n",
    "  u'0.015*business + 0.010*experience + 0.009*requirements + 0.009*management + 0.008*project + 0.008*data + 0.008*support + 0.007*work'),\n",
    " (3,\n",
    "  u'0.008*experience + 0.007*work + 0.006*solutions + 0.006*management + 0.006*program + 0.006*business + 0.005*client + 0.005*services'),\n",
    " (4,\n",
    "  u'0.016*experience + 0.011*security + 0.011*systems + 0.008*analysis + 0.008*management + 0.008*information + 0.007*requirements + 0.007*related'),\n",
    " (5,\n",
    "  u'0.019*business + 0.010*marketing + 0.010*data + 0.009*experience + 0.009*management + 0.009*team + 0.008*skills + 0.007*analysis'),\n",
    " (6,\n",
    "  u'0.018*health + 0.015*care + 0.009*experience + 0.008*clinical + 0.008*data + 0.007*healthcare + 0.007*research + 0.007*hospital'),\n",
    " (7,\n",
    "  u'0.017*search + 0.014*seo + 0.010*marketing + 0.008*campaigns + 0.007*experience + 0.006*google + 0.006*paid + 0.006*tools'),\n",
    " (8,\n",
    "  u'0.011*information + 0.009*experience + 0.008*required + 0.008*service + 0.008*systems + 0.007*application + 0.006*data + 0.006*work'),\n",
    " (9,\n",
    "  u'0.015*marketing + 0.013*business + 0.008*project + 0.007*management + 0.007*product + 0.007*experience + 0.006*team + 0.006*work')]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Part 7: Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NLP, jobs will be associated with one another to gather similar jobs. The job descriptions will be split into word vectors and will be used for comparison, using cosine similarity calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original Posting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "The Discovery wing of the Data Analytics and Engineering (DEA) team focuses on analytics of the core features of the Netflix product - Kids, Title Merchandising, Personalization, Billboard, Post Play, Ratings, My List (aka Queue), Popularity of UI features, Netflix Originals promotions etc. These areas are constantly evolving to improve our users personalized experience worldwide. The best part is, the work you do helps in shaping the future of Netflix product and fun part is, as a consumer can see and feel the difference.\n",
    "\n",
    "\n",
    "We are looking for an individual with following characteristics - exceptional analytical skills, passion for data, looking for a fast pace environment, dislikes micromanagement, explore creative and innovative ideas, not afraid of failures, eager to collaborate, good listener and has courage to challenge ideas. You will partner directly with the Product Innovation directors to analyze user behavior data, help them understand how users are consuming content and help them innovate Netflix product.\n",
    "\n",
    "\n",
    "Problems we are solving:\n",
    "\n",
    "What metrics should we use to measure the success of our product features? How do Kids use our product compared to adult? How to evolve the product for global landscape - regional difference, language difference, cultural difference etc.? What does a user’s interaction behavior tell us about their engagement/retention?\n",
    "\n",
    "\n",
    "What you’ll do\n",
    "\n",
    "\n",
    "Mine and analyze data pertaining to customers’ discovery and viewing experiences to identify critical actionable product insights.\n",
    "Proactively develop new metrics and studies to quantify the value of different aspects of discovery features, and set up ongoing reports to continually measure their performance.\n",
    "Translate analytic insights into concrete, actionable recommendations for business or product improvement.\n",
    "Partner closely with product managers and engineering leaders throughout the lifecycle of launching new Netflix features. Ensure that analytic needs are well-defined up front, and development timelines are coordinated with analytic needs.\n",
    "Drive efforts to enable product managers and engineering leaders to share your knowledge and insights through clear and concise communication, education, and data visualization.\n",
    "\n",
    "\n",
    "Who you are:\n",
    "\n",
    "\n",
    "5+ years of experience in data analysis to derive impactful insights.\n",
    "Strong interpersonal and communication skills: ability to tell a clear, concise, actionable story with data.\n",
    "Proficiency at querying high volume data using SQL, and pulling data from various sources (e.g. log files, Redshift).\n",
    "Strong data visualization skills (Tableau).\n",
    "Experience with big data technologies - Hadoop, Hive, Presto, etc.\n",
    "Good understanding of high-level product architecture and data flow patterns.\n",
    "\n",
    "\n",
    "A few more things to know:\n",
    "\n",
    "\n",
    "Our culture is unique and we live by our values, so it’s worth learning more about Netflix at www.netflix.com/Jobs.\n",
    "You will need to be comfortable working in the most agile of environments. Requirements will be vague. Iterations will be rapid. You will need to be nimble and take smart risks.\n",
    "\n",
    "30+ \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### similarity rating: (0.63400555872866082, 190)\n",
    "```\n",
    "============================================\n",
    "The Discovery wing of the Data Analytics and Engineering (DEA) team focuses on analytics of the core Netflix product features - Original content promotion, Kids, feature performance, etc. In addition to learning about user’s behavior through product usage, we also partner with consumer insight business team to understand the user's behavior/perception of product and in general Netflix brand by conducting quantitative and qualitative study.\n",
    "\n",
    "\n",
    "We are looking for an individual with following characteristics - strong analytical skills, passion for data, looking for a fast paced environment, self starter, explore creative and innovative ideas, eager to collaborate. You will partner directly with the consumer insight team to support their data need to conduct quantitative/qualitative studies and analytics requirement. You will also work with other product innovation director to help them understand how users are interacting with product and partner with them to innovate product.\n",
    "\n",
    "\n",
    "Problems we are solving :\n",
    "\n",
    "What metrics should we use to measure the success of our product features? How do Kids use our product compared to adult? How to evolve the product for global landscape - regional difference, language difference, cultural difference etc.? What does a user’s interaction behavior tell us about their engagement/retention?\n",
    "\n",
    "\n",
    "What you’ll do\n",
    "\n",
    "\n",
    "Mine and analyze data pertaining to customers’ discovery and viewing experiences to support quantitative and qualitative study.\n",
    "Develop insightful reports/dashboard for business to self serve\n",
    "Develop new metrics to measure the impact of discovery features\n",
    "Partner with product managers and engineering leaders to help innovate product\n",
    "\n",
    "\n",
    "Who you are:\n",
    "\n",
    "\n",
    "1+ years of data analytics experience\n",
    "Strong SQL background, and proficient in pulling data from different sources (e.g. log files, Redshift).\n",
    "Strong interpersonal and communication skills\n",
    "Strong data visualization skills (Tableau)\n",
    "Experience with big data technologies (Hadoop, Hive, Presto) is a plus\n",
    "\n",
    "\n",
    "A few more things to know:\n",
    "\n",
    "\n",
    "Our culture is unique and we live by our values, so it’s worth learning more about Netflix atwww.netflix.com/Jobs.\n",
    "You will need to be comfortable working in the most agile of environments. Requirements will be vague. Iterations will be rapid. You will need to be nimble and take smart risks.\n",
    "```\n",
    "5 \n",
    "#### similarity rating: (0.29482984870228707, 31)\n",
    "\n",
    "```\n",
    "============================================\n",
    "\n",
    "Our client-partner is a leading eCommerce services company – they are one of Canada’s fastest-growing and most innovative Internet companies. As the Business Intelligence Product Manager, you will be responsible for working on a talented team of Data Science and Business Intelligence professionals.\n",
    "\n",
    "\n",
    "In this role you will be responsible for defining BI product strategy and collaborating with engineering to bring business intelligence and reporting solutions from conception to delivery. You will establish strong working relationships with internal and external clients, aggregate requirements, build a product roadmap, and manage the life cycle of new and existing BI technology initiatives.\n",
    "\n",
    "\n",
    "Responsibilities\n",
    "\n",
    "Work with internal clients to understand, document, support, and re-envision the reporting and tools that support a variety of business processes.\n",
    "Work with the Relationship Management team and loyalty partner representatives to understand partner reporting and data requirements.\n",
    "Define all aspects of business intelligence product requirements and specifications, including mockups, detailed definitions, external data source integrations, internal data and transaction flows, and operational and product adoption documentation\n",
    "Work closely with the Product Managers, Directors, and VP of Product to drive an understanding of business intelligence throughout all product development work at the company.\n",
    "Use Agile product delivery practices; working closely with a scrum master, software engineering and QA to build, test, release, and measure all product initiatives.\n",
    "Manage a product backlog, project timelines, scope, milestones, and prioritization.\n",
    "\n",
    "Required Skills\n",
    "\n",
    "3+ years of hands-on experience in software/internet product management\n",
    "A curiosity for and desire to work with data products (this could be databases, data warehousing concepts, BI reporting tools or business data visualization tools).\n",
    "Comfortable writing SQL to explore data sets and perform basic manipulations.\n",
    "An understanding of strategic trends in data (e.g. predictive analytics, big data, machine learning) and how they relate to Business Intelligence.\n",
    "Experience in defining requirements for reports and underlying ETL processes.\n",
    "Familiarity with ecommerce development, Web Services, and related areas.\n",
    "Computer Science or Engineering degree, or significant technical work experience.\n",
    "Experience in an eCommerce environment is highly advantageous\n",
    "Hands-on experience with client interfacing for requirements analysis, developing multi-phase feature roadmaps, ongoing communication with clients, granular feature prioritization, detailed feature design and documentation of product/functional requirement specifications.\n",
    "Detail-oriented, able to bring clarity to complex situations, and skilled at bridging the gap between technical and non-technical audiences.\n",
    "Strongly analytic, able to find patterns in data, and skilled at understanding a diverse set of transactional processes.\n",
    "Results-oriented at an individual and team level, ambitious, and strong ability to follow-through on commitments.\n",
    "Previous experience with Agile development practices.\n",
    "\n",
    "30+ \n",
    "```\n",
    "#### similarity rating: (0.29460614637750837, 215)\n",
    "\n",
    "```\n",
    "============================================\n",
    "\n",
    "Vencore is a proven provider of information solutions, engineering and analytics for the U.S. Government. With more than 40 years of experience working in the defense, civilian and intelligence communities, Vencore designs, develops and delivers high impact, mission-critical services and solutions to overcome its customers most complex problems.\n",
    "\n",
    "\n",
    "Headquartered in Chantilly, Virginia, Vencore employs 3,800 engineers, analysts, IT specialists and other professionals who strive to be the best at everything they do.\n",
    "\n",
    "\n",
    "Vencore is an AA/EEO Employer - Minorities/Women/Veterans/Disabled\n",
    "\n",
    "\n",
    "Responsibilities:\n",
    "The M&S Data Architect will develop a detailed knowledge of the underlying data and data products and become the subject matter expert on content, current and potential future uses of data, and the quality and interrelationship between core elements of the data repository and data products.\n",
    "\n",
    "\n",
    "The M&S Data Architect will consult with information technology and M&S staff to design and implement scripts, programs, databases, software components and analysis that will support product quality and an in depth understanding of potential uses of the data.\n",
    "\n",
    "\n",
    "Performs a key leadership role in the areas of advanced data techniques, including data modeling, data access, data integration, data visualization, text mining, data discovery, statistical methods, database design and implementation.\n",
    "\n",
    "\n",
    "Defines and achieves the strategy roadmap for the enterprise; including data modeling, implementation and data management for the enterprise data warehouse and advanced data analytics systems.\n",
    "\n",
    "\n",
    "Establishes standards and guidelines for the design & development, tuning, deployment and maintenance of information, advanced data analytics, and text mining models and physical data persistence technologies.\n",
    "\n",
    "\n",
    "Provides leadership in establishing analytic environments required for structured, semi-structured and unstructured data.\n",
    "\n",
    "\n",
    "Works with staff and customers to understand the business requirements and business processes, design data warehouse (\"DW\") schema and define extract-translate-load (\"ETL\") and/or extract-load-translate (\"ELT\") processes for DW.\n",
    "\n",
    "\n",
    "Utilization of advanced data analysis, including statistical analysis, data mining techniques, and use of computational packages such as SAS, R or SPSS.\n",
    "\n",
    "\n",
    "Qualifications:\n",
    "Required Qualifications:\n",
    "\n",
    "BS in Electrical/Computer Engineering, Computer Science, Math, Physics, or equivalent, with 5 or more years of relevant experience in a DoD-related program or similar.\n",
    "\n",
    "\n",
    "-Experience in Data Management, Data Storage and Data Analysis.\n",
    "\n",
    "-Technical knowledge with; Big Data storage & analytics, Information Science, Software Development and Databases, Systems Security process and systems engineering.\n",
    "\n",
    "-Proven experience converting large ambiguous data sets into compact visualizations, and transitioning code and requirements to developers.\n",
    "\n",
    "-Experience defining/architecting end-to-end data flow and data management systems, and multi-system/multi-software interface definition & documentation.\n",
    "\n",
    "-Strong experience working directly with non-technical customers and translating requirements into actionable prototypes, and developing formal requirements for such prototypes.\n",
    "\n",
    "-Strong knowledge and experience of software development, modern database and indexing theories.\n",
    "\n",
    "-Strong knowledge and experience of different data storage, search, and retrieval models\n",
    "\n",
    "\n",
    "Security: Top Secret Clearance is required.\n",
    "\n",
    "6 \n",
    "```\n",
    "#### similarity rating: (0.29166454034940587, 464)\n",
    "\n",
    "```\n",
    "============================================\n",
    "\n",
    "Amazon Relational Database Service (Amazon RDS) is an industry leading web service that makes it easy to set up, operate, and scale a relational database in the cloud using any of the leading database engines – MySQL, MariaDB, PostgreSQL, SQL Server and Oracle, as well as Amazon’s own MySQL-compatible database engine, Aurora. We are looking for a for a seasoned and talented data engineer to join the team in our Seattle Headquarters. More information on Amazon RDS is available at http://aws.amazon.com/rds.\n",
    "\n",
    "\n",
    "The data engineer must be passionate about data and the insights that large amounts of data can provide and has the ability to contribute major novel innovations for our team. The role will focus on working with a team of product and program managers, engineering leaders and business leaders to build pipelines and data analysis tools to help the organization run it’s business better. The role will focus on business insights, deep data and trend analysis, operational monitoring and metrics as well as new ideas we haven’t had yet (but you’ll help us have!). The ideal candidate will possess both a data engineering background and a strong business acumen that enables him/her to think strategically and add value to help us improve the RDS customer experience. He/she will experience a wide range of problem solving situations, strategic to real-time, requiring extensive use of data collection and analysis techniques such as data mining and machine learning. In addition, the data engineering role will act as a foundation for the business intelligence team and be forward facing to all levels within the organization.\n",
    "\n",
    "\n",
    "· Develop and improve the current data architecture for RDS\n",
    "\n",
    "· Drive insights into how our customers use RDS, how successful they are, where our revenue trends are going up or down, how we are helping customers have a remarkable experience, etc.\n",
    "\n",
    "· Improve upon the data ingestion models, ETLs, and alarming to maintain data integrity and data availability.\n",
    "\n",
    "· Keep up to date with advances in big data technologies and run pilots to design the data architecture to scale with the increased data sets of RDS.\n",
    "\n",
    "· Partner with BAs across teams such as product management, operations, sales, marketing and engineering to build and verify hypotheses.\n",
    "\n",
    "· Manage and report via dashboards and papers the results of daily, weekly, and monthly reporting\n",
    "\n",
    "\n",
    "Basic Qualifications\n",
    "Basic Qualifications\n",
    "\n",
    "· Bachelor's Degree in Computer Science or a related technical field.\n",
    "\n",
    "· 6+ years of experience developing data management systems, tools and architectures using SQL, databases, Redshift and/or other distributed computing systems.\n",
    "\n",
    "· Familiarity with new advances in the data engineering space such as EMR and NoSQL technologies like Dynamo DB.\n",
    "\n",
    "· Experience designing and operating very large Data Warehouses.\n",
    "\n",
    "· Demonstrated strong data modelling skills in areas such as data mining and machine learning.\n",
    "\n",
    "· Proficient in Oracle, Linux, and programming languages such as R, Python, Ruby or Java.\n",
    "\n",
    "· Skilled in presenting findings, metrics and business information to a broad audience consisting of multiple disciplines and all levels or the organizations.\n",
    "\n",
    "· Track record for quickly learning new technologies.\n",
    "\n",
    "· Solid experience in at least one business intelligence reporting tool, e.g. Tableau.\n",
    "\n",
    "· An ability to work in a fast-paced environment where continuous innovation is occurring and ambiguity is the norm.\n",
    "\n",
    "\n",
    "Preferred Qualifications\n",
    "Preferred Qualification\n",
    "\n",
    "· Master’s degree in Information Systems or a related field.\n",
    "\n",
    "· Capable of investigating, familiarizing and mastering new datasets quickly.\n",
    "\n",
    "· Knowledge of a programming or scripting language (R, Python, Ruby, or JavaScript).\n",
    "\n",
    "· Experience with MPP databases such as Greenplum, Vertica, or Redshift\n",
    "\n",
    "· Experience with Java and Map Reduce frameworks such as Hive/Hadoop.\n",
    "\n",
    "· 1+ years of experience managing an Analytic or Data Engineering team.\n",
    "\n",
    "· Strong organizational and multitasking skills with ability to balance competing priorities.\n",
    "\n",
    "Amazon.com - 8 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8 - Clustering by Hard Skills by jobname NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
