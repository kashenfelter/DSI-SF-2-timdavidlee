{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R3 - Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print '\\n============= Count X 22,000'\n",
    "tM = topicModeling(alltext,verbose=1)\n",
    "vec = CountVectorizer(stop_words='english', ngram_range=(1,1), min_df =2,max_features=50000)\n",
    "tM.setVectorizer(vec)\n",
    "tM.fitText()\n",
    "tM.fitTopics(topic_ct=5,passes=25)\n",
    "tM.printTopics()\n",
    "tM.save('ALL22k05')\n",
    "\n",
    "\n",
    "print '\\n============= Count X 22,000'\n",
    "tM.fitTopics(topic_ct=10,passes=25)\n",
    "\n",
    "\n",
    "print '\\n============ word frequencies =================='\n",
    "print tM.wordFreq[:20]\n",
    "print '\\n============ topics found === =================='\n",
    "tM.printTopics()\n",
    "tM.save('ALL22k10')\n",
    "\n",
    "\n",
    "\n",
    "print '\\n============= Count X 22,000'\n",
    "tM.fitTopics(topic_ct=25,passes=25)\n",
    "\n",
    "print '\\n============ word frequencies =================='\n",
    "print tM.wordFreq[:20]\n",
    "print '\\n============ topics found === =================='\n",
    "tM.printTopics()\n",
    "tM.save('ALL22k25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of some of the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Text .fitText()\n",
    "\n",
    "Fit text accomplishes 3 main tasks - \n",
    "1. Turns the complete job posting into words/counts with Count Vectorizer\n",
    "2. Creates the corpus for LDA modeling\n",
    "3. Creates the vocab for LDA modeling\n",
    "4. Also stores the array for future usage in a Dataframe format\n",
    "\n",
    "```\n",
    "def fitText(self):\n",
    "        start = datetime.datetime.now()\n",
    "        self.verboseMsg('text===>word start: fitting text of size %d documents' % (len(self.sometext)))\n",
    "\n",
    "        self.X = self.vectorizer.fit_transform(self.sometext)\n",
    "\n",
    "        self.verboseMsg('text===>word summarizing vocab and creating corpus ')\n",
    "\n",
    "        #prepping summary\n",
    "        self.df_X = pd.DataFrame(self.X.toarray(), columns=self.vectorizer.get_feature_names())\n",
    "        self.wordFreq = self.df_X.sum().sort_values(ascending = False)        \n",
    "\n",
    "        self.vocab = {v: k for k, v in self.vectorizer.vocabulary_.iteritems()}\n",
    "        self.corpus = matutils.Sparse2Corpus(self.X, documents_columns=False)    \n",
    "\n",
    "        self.verboseMsg('text===>word complete. ')\n",
    "        print datetime.datetime.now() - start\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Topics .fitTopics()\n",
    "\n",
    "Fit topics run the multi-core version of LDA on AWS, (workers = 5) is similar to the n_jobs notation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A: Topic Modeling Runtime Class (to keep everything together)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import cPickle as pickle\n",
    "from gensim import corpora, models, matutils\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "class topicModeling(object):\n",
    "    margin = '\\t\\t'\n",
    "    def verboseMsg(self, msg):\n",
    "        if self.verbose:\n",
    "            print self.margin, msg\n",
    "        \n",
    "    def __init__(self, alltext, verbose=0):\n",
    "        self.sometext = alltext\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def loadText(self,alltext):\n",
    "        self.sometext = alltext\n",
    "    \n",
    "    def setVectorizer(self,vectorizer):\n",
    "        self.vectorizer = vectorizer\n",
    "    \n",
    "    def setCvec(self,ngram_range):\n",
    "        self.vectorizer = CountVectorizer(stop_words='english', ngram_range=ngram_range)\n",
    "    \n",
    "    def setTvec(self,ngram_range):\n",
    "        self.vectorizer = TfidfVectorizer(stop_words='english', ngram_range=ngram_range)\n",
    "        \n",
    "    def fitText(self):\n",
    "        start = datetime.datetime.now()\n",
    "        self.verboseMsg('text===>word start: fitting text of size %d documents' % (len(self.sometext)))\n",
    "            \n",
    "        self.X = self.vectorizer.fit_transform(self.sometext)\n",
    "        \n",
    "        self.verboseMsg('text===>word summarizing vocab and creating corpus ')\n",
    "        \n",
    "        #prepping summary\n",
    "        self.df_X = pd.DataFrame(self.X.toarray(), columns=self.vectorizer.get_feature_names())\n",
    "        self.wordFreq = self.df_X.sum().sort_values(ascending = False)        \n",
    "    \n",
    "        self.vocab = {v: k for k, v in self.vectorizer.vocabulary_.iteritems()}\n",
    "        self.corpus = matutils.Sparse2Corpus(self.X, documents_columns=False)    \n",
    "        \n",
    "        self.verboseMsg('text===>word complete. ')\n",
    "        print datetime.datetime.now() - start\n",
    "            \n",
    "    def fitTopics(self,topic_ct,passes):\n",
    "        start = datetime.datetime.now()        \n",
    "        self.topic_ct = topic_ct\n",
    "        self.passes = passes\n",
    "        \n",
    "        self.verboseMsg('worp===>%d topics, %d passes: start ' %(topic_ct,passes))\n",
    "        self.lda = models.LdaMulticore(\n",
    "            self.corpus,\n",
    "            num_topics  =  self.topic_ct,\n",
    "            passes      =  passes,\n",
    "            id2word     =  self.vocab,\n",
    "            workers = 4,\n",
    "            iterations = 2500,\n",
    "            eval_every = 100,\n",
    "            chunksize = 2000\n",
    "        )\n",
    "        self.verboseMsg('worp===>%d topics, %d passes: lda model complete ' %(topic_ct,passes))\n",
    "        \n",
    "        self.topic_vectors = self.lda.print_topics(num_topics=self.topic_ct, num_words=8)\n",
    "\n",
    "        self.topic_proba = []\n",
    "        for x in self.corpus:\n",
    "            local = self.lda.get_document_topics(x)\n",
    "            row = { x:float(0) for x in range(self.topic_ct)}\n",
    "            for y in local:\n",
    "                row[y[0]] = y[1]\n",
    "            self.topic_proba.append(row)\n",
    "\n",
    "        self.verboseMsg('worp===>%d topics, %d passes: creating probabilities in dataframe ' %(topic_ct,passes))\n",
    "        \n",
    "        self.topic_proba_df = pd.DataFrame(self.topic_proba)\n",
    "    \n",
    "        self.verboseMsg('worp===>%d topics, %d passes: complete ' %(topic_ct,passes))\n",
    "        print datetime.datetime.now() - start\n",
    "    def printTopics(self):\n",
    "        for topic in self.topic_vectors:\n",
    "            print '========================================'\n",
    "            print 'topic number:', topic[0]\n",
    "            for y in topic[1].split('+'):\n",
    "                print '\\t',y\n",
    "\n",
    "    def save(self,prefix='_'):\n",
    "        suffix = str(int(time.mktime(datetime.datetime.now().timetuple())))[-6:]\n",
    "        with open(\"z003_\"+prefix+\"_topic_proba_df_dict_\"+suffix+\".p\",'wb') as f:\n",
    "            pickle.dump(self.topic_proba_df,f)\n",
    "        with open(\"z003_\"+prefix+\"_topic_vectors_\"+suffix+\".p\",'wb') as f:\n",
    "            pickle.dump(self.topic_vectors,f)\n",
    "        with open(\"z003_\"+prefix+\"_X_\"+suffix+\".p\",'wb') as f:\n",
    "            pickle.dump(self.df_X,f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix B: AWS Run Code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "from gensim import corpora, models, matutils\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from topicModelingClass import topicModeling\n",
    "\n",
    "\n",
    "#=========================================================================================================\n",
    "#=========================================================================================================\n",
    "#=========================================================================================================\n",
    "# main run time\n",
    "\n",
    "with open('../jNotebooks/master_total_df.p','rb') as f:\n",
    "    master_total_df = pickle.load(f)\n",
    "master_total_df.head(2)\n",
    "alltext = master_total_df['jobdesc'].values\n",
    "\n",
    "\n",
    "print '\\n============= Count Vec'\n",
    "tM = topicModeling(alltext[:100],verbose=1)\n",
    "vec = CountVectorizer(stop_words='english', ngram_range=(1,1), min_df =2,max_features=50000)\n",
    "tM.setVectorizer(vec)\n",
    "tM.fitText()\n",
    "tM.fitTopics(topic_ct=3,passes=20)\n",
    "\n",
    "\n",
    "print '\\n============ word frequencies =================='\n",
    "print tM.wordFreq[:20]\n",
    "print '\\n============ topics found === =================='\n",
    "tM.printTopics()\n",
    "\n",
    "\n",
    "print '\\n============= Tfidf'\n",
    "tM = topicModeling(alltext[:100],verbose=1)\n",
    "vec = TfidfVectorizer(stop_words='english', ngram_range=(1,1), min_df =2,max_features=50000)\n",
    "tM.setVectorizer(vec)\n",
    "tM.fitText()\n",
    "tM.fitTopics(topic_ct=3,passes=3)\n",
    "\n",
    "print '\\n============ word frequencies =================='\n",
    "print tM.wordFreq[:20]\n",
    "print '\\n============ topics found === =================='\n",
    "tM.printTopics()\n",
    "\n",
    "\n",
    "\n",
    "print '\\n============= Count X 22,000'\n",
    "tM = topicModeling(alltext,verbose=1)\n",
    "vec = CountVectorizer(stop_words='english', ngram_range=(1,1), min_df =2,max_features=50000)\n",
    "tM.setVectorizer(vec)\n",
    "tM.fitText()\n",
    "tM.fitTopics(topic_ct=5,passes=25)\n",
    "tM.printTopics()\n",
    "tM.save('ALL22k05')\n",
    "\n",
    "\n",
    "print '\\n============= Count X 10,000'\n",
    "tM.fitTopics(topic_ct=10,passes=25)\n",
    "\n",
    "\n",
    "print '\\n============ word frequencies =================='\n",
    "print tM.wordFreq[:20]\n",
    "print '\\n============ topics found === =================='\n",
    "tM.printTopics()\n",
    "tM.save('ALL22k10')\n",
    "\n",
    "\n",
    "\n",
    "print '\\n============= Count X 10,000'\n",
    "tM.fitTopics(topic_ct=25,passes=25)\n",
    "\n",
    "print '\\n============ word frequencies =================='\n",
    "print tM.wordFreq[:20]\n",
    "print '\\n============ topics found === =================='\n",
    "tM.printTopics()\n",
    "tM.save('ALL22k25')\n",
    "\n",
    "\n",
    "print '\\n============= Count X 10,00 ngram 2'\n",
    "tM = topicModeling(alltext,verbose=1)\n",
    "vec = CountVectorizer(stop_words='english', ngram_range=(2,2), min_df =2,max_features=50000)\n",
    "tM.setVectorizer(vec)\n",
    "tM.fitText()\n",
    "tM.fitTopics(topic_ct=10,passes=25)\n",
    "\n",
    "print '\\n============ word frequencies =================='\n",
    "print tM.wordFreq[:20]\n",
    "print '\\n============ topics found === =================='\n",
    "tM.printTopics()\n",
    "tM.save('ALL22k2G25')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix C: AWS Console Response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "============= Count Vec\n",
    "\t\ttext===>word start: fitting text of size 100 documents\n",
    "\t\ttext===>word summarizing vocab and creating corpus\n",
    "\t\ttext===>word complete.\n",
    "0:00:00.056617\n",
    "\t\tworp===>3 topics, 20 passes: start\n",
    "\t\tworp===>3 topics, 20 passes: lda model complete\n",
    "\t\tworp===>3 topics, 20 passes: creating probabilities in dataframe\n",
    "\t\tworp===>3 topics, 20 passes: complete\n",
    "0:00:28.173462\n",
    "\n",
    "============ word frequencies ==================\n",
    "data           478\n",
    "experience     406\n",
    "business       322\n",
    "work           238\n",
    "team           227\n",
    "skills         224\n",
    "ability        172\n",
    "analytics      158\n",
    "development    157\n",
    "management     152\n",
    "marketing      150\n",
    "solutions      148\n",
    "support        145\n",
    "years          132\n",
    "strong         128\n",
    "technical      125\n",
    "systems        122\n",
    "knowledge      119\n",
    "new            118\n",
    "design         113\n",
    "dtype: int64\n",
    "\n",
    "============ topics found === ==================\n",
    "========================================\n",
    "topic number: 0\n",
    "\t0.015*experience\n",
    "\t 0.009*business\n",
    "\t 0.009*team\n",
    "\t 0.009*marketing\n",
    "\t 0.008*development\n",
    "\t 0.007*skills\n",
    "\t 0.006*solutions\n",
    "\t 0.006*work\n",
    "========================================\n",
    "topic number: 1\n",
    "\t0.020*data\n",
    "\t 0.014*business\n",
    "\t 0.013*experience\n",
    "\t 0.010*work\n",
    "\t 0.009*skills\n",
    "\t 0.008*management\n",
    "\t 0.007*ability\n",
    "\t 0.007*project\n",
    "========================================\n",
    "topic number: 2\n",
    "\t0.025*data\n",
    "\t 0.011*experience\n",
    "\t 0.008*business\n",
    "\t 0.008*team\n",
    "\t 0.007*analytics\n",
    "\t 0.007*work\n",
    "\t 0.007*product\n",
    "\t 0.007*skills\n",
    "\n",
    "============= Tfidf\n",
    "\t\ttext===>word start: fitting text of size 100 documents\n",
    "\t\ttext===>word summarizing vocab and creating corpus\n",
    "\t\ttext===>word complete.\n",
    "0:00:00.061992\n",
    "\t\tworp===>3 topics, 3 passes: start\n",
    "\t\tworp===>3 topics, 3 passes: lda model complete\n",
    "\t\tworp===>3 topics, 3 passes: creating probabilities in dataframe\n",
    "\t\tworp===>3 topics, 3 passes: complete\n",
    "0:00:03.488978\n",
    "\n",
    "============ word frequencies ==================\n",
    "data           9.255721\n",
    "experience     6.865504\n",
    "business       6.360939\n",
    "marketing      5.236011\n",
    "work           4.318256\n",
    "skills         4.071426\n",
    "team           3.899816\n",
    "ability        3.454123\n",
    "development    3.273708\n",
    "analytics      3.246132\n",
    "management     3.202498\n",
    "product        3.198152\n",
    "systems        3.158345\n",
    "solutions      3.124353\n",
    "support        3.093322\n",
    "software       3.025688\n",
    "client         3.024107\n",
    "strong         2.862458\n",
    "design         2.831874\n",
    "years          2.788880\n",
    "dtype: float64\n",
    "\n",
    "============ topics found === ==================\n",
    "========================================\n",
    "topic number: 0\n",
    "\t0.002*marketing\n",
    "\t 0.002*data\n",
    "\t 0.002*business\n",
    "\t 0.002*systems\n",
    "\t 0.001*experience\n",
    "\t 0.001*solutions\n",
    "\t 0.001*team\n",
    "\t 0.001*skills\n",
    "========================================\n",
    "topic number: 1\n",
    "\t0.004*data\n",
    "\t 0.003*experience\n",
    "\t 0.003*business\n",
    "\t 0.002*marketing\n",
    "\t 0.002*product\n",
    "\t 0.002*skills\n",
    "\t 0.002*work\n",
    "\t 0.002*team\n",
    "========================================\n",
    "topic number: 2\n",
    "\t0.002*data\n",
    "\t 0.002*experience\n",
    "\t 0.002*business\n",
    "\t 0.002*project\n",
    "\t 0.002*work\n",
    "\t 0.001*job\n",
    "\t 0.001*content\n",
    "\t 0.001*required\n",
    "\n",
    "============= Count X 22,000\n",
    "\t\ttext===>word start: fitting text of size 22707 documents\n",
    "\t\ttext===>word summarizing vocab and creating corpus\n",
    "\t\ttext===>word complete.\n",
    "0:00:18.749236\n",
    "\t\tworp===>5 topics, 25 passes: start\n",
    "\t\tworp===>5 topics, 25 passes: lda model complete\n",
    "\t\tworp===>5 topics, 25 passes: creating probabilities in dataframe\n",
    "\t\tworp===>5 topics, 25 passes: complete\n",
    "0:25:45.134110\n",
    "========================================\n",
    "topic number: 0\n",
    "\t0.022*business\n",
    "\t 0.013*experience\n",
    "\t 0.012*management\n",
    "\t 0.010*requirements\n",
    "\t 0.009*skills\n",
    "\t 0.008*project\n",
    "\t 0.008*work\n",
    "\t 0.007*ability\n",
    "========================================\n",
    "topic number: 1\n",
    "\t0.023*experience\n",
    "\t 0.014*software\n",
    "\t 0.014*data\n",
    "\t 0.011*learning\n",
    "\t 0.010*systems\n",
    "\t 0.010*development\n",
    "\t 0.010*machine\n",
    "\t 0.008*engineering\n",
    "========================================\n",
    "topic number: 2\n",
    "\t0.057*data\n",
    "\t 0.019*business\n",
    "\t 0.016*experience\n",
    "\t 0.012*analytics\n",
    "\t 0.010*analysis\n",
    "\t 0.009*skills\n",
    "\t 0.007*ability\n",
    "\t 0.006*work\n",
    "========================================\n",
    "topic number: 3\n",
    "\t0.010*status\n",
    "\t 0.009*employment\n",
    "\t 0.009*work\n",
    "\t 0.007*opportunity\n",
    "\t 0.007*company\n",
    "\t 0.006*disability\n",
    "\t 0.006*information\n",
    "\t 0.006*equal\n",
    "========================================\n",
    "topic number: 4\n",
    "\t0.015*experience\n",
    "\t 0.012*team\n",
    "\t 0.011*data\n",
    "\t 0.010*work\n",
    "\t 0.009*product\n",
    "\t 0.009*marketing\n",
    "\t 0.006*new\n",
    "\t 0.006*digital\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
